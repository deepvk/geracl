# GeRaCl: General Rapid text Classifier

**GeRaCl** is an open‚Äësource **framework** for building, training, and evaluating efficient zero‚Äëshot text classifiers on top of any BERT‚Äëlike sentence-encoder. It is inspired by the [GLiNER](https://github.com/urchade/GLiNER/tree/main) framework.

### ‚ú®¬†Why GeRaCl?

| Feature                        | What it means for you                                                                             |
| ------------------------------ | ------------------------------------------------------------------------------------------------- |
| **Zero‚Äëshot by design**        | Classify with **arbitrary** label sets that you decide at run‚Äëtime ‚Äî just pass a list of strings. |
| **One forward pass**           | As fast as ordinary text classification; no pairwise loops like in NLI‚Äëbased approaches.          |
| **Model‚Äëagnostic**             | Works with any Hugging¬†Face sentence-encoder.                                                     |
| **155‚ÄØM¬†reference checkpoint** | A lean [baseline](https://huggingface.co/deepvk/GeRaCl-USER2-base) (155M parameters) that beats much larger sentence‚Äëencoders (300-500M parameters). |
| **All‚Äëin‚Äëone toolkit**         | Training/eval scripts, HF Hub and WandB integration.                                              |


### üöÄ Quick Start

Clone and install directly from GitHub:

```bash
git clone https://github.com/deepvk/geracl
cd geracl

pip install -r requirements.txt
```

Verify your installation:

```python
import geracl
print(geracl.__version__)
```

### üßë‚Äçüíª Usage Examples

#### Single classification scenario

```python
from transformers import AutoTokenizer
from geracl import GeraclHF, ZeroShotClassificationPipeline

model = GeraclHF.from_pretrained('deepvk/GeRaCl-USER2-base').to('cuda').eval()
tokenizer  = AutoTokenizer.from_pretrained('deepvk/GeRaCl-USER2-base')

pipe = ZeroShotClassificationPipeline(model, tokenizer, device="cuda")

text = "–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ç–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: –∫–∞–∫ –Ω–µ–ø–ª–æ—Ö–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å"
labels = ["—ç–∫–æ–Ω–æ–º–∏–∫–∞", "–ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–∫—É–ª—å—Ç—É—Ä–∞", "–Ω–∞—É–∫–∞", "—Å–ø–æ—Ä—Ç"]
result = pipe(text, labels, batch_size=1)[0]

print(labels[result])
```

#### Multiple classification scenarios

```python
from transformers import AutoTokenizer
from geracl import GeraclHF, ZeroShotClassificationPipeline

model = GeraclHF.from_pretrained('deepvk/GeRaCl-USER2-base').to('cuda').eval()
tokenizer  = AutoTokenizer.from_pretrained('deepvk/GeRaCl-USER2-base')

pipe = ZeroShotClassificationPipeline(model, tokenizer, device="cuda")

texts = [
  "–£—Ç–∏–ª–∏–∑–∞—Ü–∏—è –∫–∞—Ç–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–≤: –∫–∞–∫ –Ω–µ–ø–ª–æ—Ö–æ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å",
  "–ú–Ω–µ –Ω–µ –ø–æ–Ω—Ä–∞–≤–∏–ª—Å—è —ç—Ç–æ—Ç —Ñ–∏–ª—å–º."
]
labels = [
  ["—ç–∫–æ–Ω–æ–º–∏–∫–∞", "–ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–∫—É–ª—å—Ç—É—Ä–∞", "–Ω–∞—É–∫–∞", "—Å–ø–æ—Ä—Ç"],
  ["–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π", "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π", "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π"]
]
results = pipe(texts, labels, batch_size=2)

for i in range(len(labels)):
    print(labels[i][results[i]])
```
